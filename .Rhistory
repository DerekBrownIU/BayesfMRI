n_sess <- length(session_names)
if(!is.list(data)) stop('I expect data to be a list, but it is not')
data_classes <- sapply(data, 'class')
if(! all.equal(unique(data_classes),'list')) stop('I expect data to be a list of lists (sessions), but it is not')
V <- ncol(data[[1]]$BOLD)
K <- ncol(data[[1]]$design)
for(s in 1:n_sess){
if(! is.session(data[[s]])) stop('I expect each element of data to be a session object, but at least one is not (see `is.session`).')
if(ncol(data[[s]]$BOLD) != V) stop('All sessions must have the same number of data locations, but they do not.')
if(ncol(data[[s]]$design) != K) stop('All sessions must have the same number of tasks (columns of the design matrix), but they do not.')
}
if(missing(mesh)) {
if(missing(mask)) mesh <- make_mesh(vertices, faces)
if(!missing(mask)) mesh <- make_mesh(vertices, faces, mask)
}
spde <- inla.spde2.matern(mesh)
#areas <- compute_vertex_areas(mesh)
#collect data and design matrices
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
if(!missing(mask)) BOLD_s <- BOLD_s[,mask==1]
#scale data to represent % signal change
BOLD_s <- scale_timeseries(t(BOLD_s))
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
#construct betas and repls objects
replicates_list <- organize_replicates(n_sess=n_sess, n_task=K, mesh=mesh)
betas <- replicates_list$betas
repls <- replicates_list$repls
#organize the formula and data objects
formula <- make_formula(beta_names = names(betas), repl_names = names(repls), model_name = 'spde', hyper_initial = c(-2,2))
environment(formula) <- globalenv()
model_data <- make_data_list(y=y_all, X=X_all_list, betas=betas, repls=repls)
#estimate model using INLA
INLA_result <- estimate_model(formula=formula, data=model_data, A=model_data$X, prec_initial=1)
#extract useful stuff from INLA model result
beta_estimates <- extract_estimates(object=INLA_result, session_names=session_names) #posterior means of latent task field
theta_posteriors <- get_posterior_densities(object=INLA_result, spde) #hyperparameter posterior densities
#identify areas of activation if activation threshold(s) specified by user
#construct object to be returned
result <- list(model=INLA_result, mesh=mesh, sessions=session_names, beta_estimates=beta_estimates, theta_posteriors=theta_posteriors)
return(result)
}
result <- BayesGLMfMRI(data, mesh=mesh)
names(result)
help(make_formula)
library(BayesGLMfMRI)
install.packages('mandymejia/BayesGLMfMRI')
library(devtools)
install_github('mandymejia/BayesGLMfMRI')
help(make_formula)
make_formula
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(BayesGLMfMRI)
library(INLA)
BayesGLMfMRI <- function(data, vertices, faces, mesh, mask, scale=TRUE){
#check whether data is a list OR a session (for single-session analysis)
#check whether each element of data is a session (use is.session)
# V0 = full number of data locations
# V = masked number of data locations
# T = length of time series for each session (vector)
# K = number of unique tasks in all sessions
#need to check that sessions are consistent in terms of V, K?
#INLA:::inla.dynload.workaround() #avoid error on creating mesh
#check that only mesh OR vertices+faces supplied
has_mesh <- !missing(mesh)
has_verts_faces <- !missing(vertices) & !missing(faces)
has_howmany <- has_mesh + has_verts_faces
if(has_howmany != 1) stop('Must supply EITHER mesh OR vertices and faces.')
#maybe also allow the user to supply a mesh object
#if mesh and mask both supplied, will need to deal with that...
#check that all elements of the data list are valid sessions and have the same number of locations and tasks
session_names <- names(data)
n_sess <- length(session_names)
if(!is.list(data)) stop('I expect data to be a list, but it is not')
data_classes <- sapply(data, 'class')
if(! all.equal(unique(data_classes),'list')) stop('I expect data to be a list of lists (sessions), but it is not')
V <- ncol(data[[1]]$BOLD)
K <- ncol(data[[1]]$design)
for(s in 1:n_sess){
if(! is.session(data[[s]])) stop('I expect each element of data to be a session object, but at least one is not (see `is.session`).')
if(ncol(data[[s]]$BOLD) != V) stop('All sessions must have the same number of data locations, but they do not.')
if(ncol(data[[s]]$design) != K) stop('All sessions must have the same number of tasks (columns of the design matrix), but they do not.')
}
if(missing(mesh)) {
if(missing(mask)) mesh <- make_mesh(vertices, faces)
if(!missing(mask)) mesh <- make_mesh(vertices, faces, mask)
}
spde <- inla.spde2.matern(mesh)
#areas <- compute_vertex_areas(mesh)
#collect data and design matrices
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
if(!missing(mask)) BOLD_s <- BOLD_s[,mask==1]
#scale data to represent % signal change
BOLD_s <- scale_timeseries(t(BOLD_s))
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
#construct betas and repls objects
replicates_list <- organize_replicates(n_sess=n_sess, n_task=K, mesh=mesh)
betas <- replicates_list$betas
repls <- replicates_list$repls
#organize the formula and data objects
formula <- make_formula(beta_names = names(betas), repl_names = names(repls), spde=spde, hyper_initial = c(-2,2))
model_data <- make_data_list(y=y_all, X=X_all_list, betas=betas, repls=repls)
#estimate model using INLA
INLA_result <- estimate_model(formula=formula, data=model_data, A=model_data$X, prec_initial=1)
#extract useful stuff from INLA model result
beta_estimates <- extract_estimates(object=INLA_result, session_names=session_names) #posterior means of latent task field
theta_posteriors <- get_posterior_densities(object=INLA_result, spde) #hyperparameter posterior densities
#identify areas of activation if activation threshold(s) specified by user
#construct object to be returned
result <- list(model=INLA_result, mesh=mesh, sessions=session_names, beta_estimates=beta_estimates, theta_posteriors=theta_posteriors)
return(result)
#   # ID AREAS OF ACTIVATION
#
#   binarize <- function(x, p){ return(x > p) }
#
#   #6 hours with cluster-wise, 2 hours with voxel-wise only
#   t0 <- Sys.time()
#   for(u in 1:U){
#
#     thr_u <- thresholds[u]
#     print(paste0('Threshold: ', thr_u))
#
#     #voxel-wise joint PPM
#     time_u <- system.time(excur_u <- id_activations(object=result, name='bbeta1', mask=mask2_sh, session_names=session_names, threshold=thr_u, alpha=0.05))
#     print(time_u)
#     row_htu <- (comptime_excur_s$hemisphere == h) & (comptime_excur_s$task_type == task_type) & (comptime_excur_s$threshold == thr_u)
#     comptime_excur_s$comptime[row_htu] <- time_u[3] #elapsed time (sec)
#     save(excur_u, file=paste(paste0('../../Results/activations/',s), sess_name, paste0(h,'_thr',thr_u,'.Rdata'), sep='_'))
#
#     for(a in c(95,99)){
#       print(paste0('Significance: ', a))
#       #voxel-wise joint PPM
#       excur_ua <- lapply(excur_u, binarize, p=a/100)
#
#       # #cluster-wise joint PPM
#       # time_ua <- system.time(excur_clust_ua <- id_activations(object=result, name='bbeta1', mask=mask2_sh, mesh=mesh_sh, session_names=session_names, threshold=thr_u, alpha=(100-a)/100, area.limit=10))
#       # row_htua <- (comptime_excur_clust_s$hemisphere == h) & (comptime_excur_clust_s$task_type == task_type) & (comptime_excur_clust_s$threshold == thr_u) & (comptime_excur_clust_s$alpha == a)
#       # comptime_excur_clust_s$comptime[row_htua] <- time_ua[3] #elapsed time (sec)
#       # excur_clust_ua <- lapply(excur_clust_ua, binarize, p=a/100)
#
#       #save activation sets for each session
#       for(v in 1:n_sess){
#         print(v)
#         sess_name <- session_names[v]
#         fname_v <- paste(paste0('../../Results/activations/',s), sess_name, paste0(h,'_thr',thr_u,'_',a,'.csv'), sep='_')
#         write.csv(excur_ua[[v]], fname_v, row.names=FALSE)
#         # fname_v <- paste(paste0('../../Results/activations/',s), sess_name, paste0(h,'_thr',thr_u,'_',a,'_clust10.csv'), sep='_')
#         # write.csv(excur_clust_ua[[v]], fname_v, row.names=FALSE)
#
#         #compute size of active area
#         inds_v <- which(excur_ua[[v]])
#         area_v <- sum(areas_full_sh[inds_v])
#         row_v <- which(paste(active_areas_sht$visit, active_areas_sht$task, sep='_')==sess_name & active_areas_sht$threshold==thr_u & active_areas_sht$significance==a)
#         active_areas_sht$area[row_v] <- area_v
#       }
#     }
#   }
#   Sys.time() - t0
#
#   active_areas_s <- rbind(active_areas_s, active_areas_sht)
#   fname <- paste0('../../Results/',s,'_activeareas.Rdata')
#   save(active_areas_s, file=fname)
#
}
getwd()
setwd('~/Dropbox/RESEARCH/BayesianGLM/SoftwarePaper/')
## Read in the mask
mask <- as.matrix(read.table("example/Mask"))
mask2 <- as.matrix(read.table("example/Mask2"))
mask3D <- mask*mask2
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
mesh <- inla.mesh.2d(loc = xy.in, boundary = boundary, max.edge = c(2, 4))
plot(mesh)
## Create a matrix to translate between original and mesh locations
Amat <- inla.spde.make.A(mesh, loc=xy.in)
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
data <- list(single_session = session)
result <- BayesGLMfMRI(data, mesh=mesh)
formula
#check that all elements of the data list are valid sessions and have the same number of locations and tasks
session_names <- names(data)
n_sess <- length(session_names)
session_names
V <- ncol(data[[1]]$BOLD)
K <- ncol(data[[1]]$design)
V
K
spde <- inla.spde2.matern(mesh)
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
BOLD_s <- scale_timeseries(t(BOLD_s))
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
#construct betas and repls objects
replicates_list <- organize_replicates(n_sess=n_sess, n_task=K, mesh=mesh)
betas <- replicates_list$betas
repls <- replicates_list$repls
#organize the formula and data objects
formula <- make_formula(beta_names = names(betas), repl_names = names(repls), spde=spde, hyper_initial = c(-2,2))
formula
BayesGLMfMRI <- function(data, vertices, faces, mesh, mask, scale=TRUE){
#check whether data is a list OR a session (for single-session analysis)
#check whether each element of data is a session (use is.session)
# V0 = full number of data locations
# V = masked number of data locations
# T = length of time series for each session (vector)
# K = number of unique tasks in all sessions
#need to check that sessions are consistent in terms of V, K?
#INLA:::inla.dynload.workaround() #avoid error on creating mesh
#check that only mesh OR vertices+faces supplied
has_mesh <- !missing(mesh)
has_verts_faces <- !missing(vertices) & !missing(faces)
has_howmany <- has_mesh + has_verts_faces
if(has_howmany != 1) stop('Must supply EITHER mesh OR vertices and faces.')
#maybe also allow the user to supply a mesh object
#if mesh and mask both supplied, will need to deal with that...
#check that all elements of the data list are valid sessions and have the same number of locations and tasks
session_names <- names(data)
n_sess <- length(session_names)
if(!is.list(data)) stop('I expect data to be a list, but it is not')
data_classes <- sapply(data, 'class')
if(! all.equal(unique(data_classes),'list')) stop('I expect data to be a list of lists (sessions), but it is not')
V <- ncol(data[[1]]$BOLD)
K <- ncol(data[[1]]$design)
for(s in 1:n_sess){
if(! is.session(data[[s]])) stop('I expect each element of data to be a session object, but at least one is not (see `is.session`).')
if(ncol(data[[s]]$BOLD) != V) stop('All sessions must have the same number of data locations, but they do not.')
if(ncol(data[[s]]$design) != K) stop('All sessions must have the same number of tasks (columns of the design matrix), but they do not.')
}
if(missing(mesh)) {
if(missing(mask)) mesh <- make_mesh(vertices, faces)
if(!missing(mask)) mesh <- make_mesh(vertices, faces, mask)
}
spde <- inla.spde2.matern(mesh)
#areas <- compute_vertex_areas(mesh)
#collect data and design matrices
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
if(!missing(mask)) BOLD_s <- BOLD_s[,mask==1]
#scale data to represent % signal change
BOLD_s <- scale_timeseries(t(BOLD_s))
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
#construct betas and repls objects
replicates_list <- organize_replicates(n_sess=n_sess, n_task=K, mesh=mesh)
betas <- replicates_list$betas
repls <- replicates_list$repls
#organize the formula and data objects
#formula <- make_formula(beta_names = names(betas), repl_names = names(repls), spde=spde, hyper_initial = c(-2,2))
formula <- y ~ -1 + f(bbeta1, model = spde, replicate = repl1, hyper = list(theta = list(initial = c(-2, 2)))) +
f(bbeta2, model = spde, replicate = repl2, hyper = list(theta = list(initial = c(-2, 2))))
model_data <- make_data_list(y=y_all, X=X_all_list, betas=betas, repls=repls)
#estimate model using INLA
INLA_result <- estimate_model(formula=formula, data=model_data, A=model_data$X, prec_initial=1)
#extract useful stuff from INLA model result
beta_estimates <- extract_estimates(object=INLA_result, session_names=session_names) #posterior means of latent task field
theta_posteriors <- get_posterior_densities(object=INLA_result, spde) #hyperparameter posterior densities
#identify areas of activation if activation threshold(s) specified by user
#construct object to be returned
result <- list(model=INLA_result, mesh=mesh, sessions=session_names, beta_estimates=beta_estimates, theta_posteriors=theta_posteriors)
return(result)
}
result <- BayesGLMfMRI(data, mesh=mesh)
names(result$beta_estimates)
names(result$beta_estimates$single_session)
class(result$beta_estimates$single_session)
head(result$beta_estimates$single_session)
dim(result$beta_estimates$single_session)
betas <- Amat %*% result$beta_estimates$single_session
dim(betas)
library(fields) #image.plot
image.nan <- function(z, zlim, col, na.color='black', xlab='', axis.args=NULL, legend=TRUE, ...){
zlim_orig <- zlim
zstep <- (zlim[2] - zlim[1]) / length(col); # step in the color palette
#newz.below.outside <- zlim[1] - zstep # new z for values below zlim
#newz.above.outside <- zlim[2] + zstep # new z for values above zlim
newz.na <- zlim[2] + 2 * zstep # new z for NA
z[which(z<zlim[1])] <- zlim[1] # we affect newz.below.outside
z[which(z>zlim[2])] <- zlim[2] # we affect newz.above.outside
z[which(is.na(z>zlim[2]))] <- newz.na # same for newz.na
#zlim[1] <- zlim[1] - zstep # extend lower limit to include below value
zlim[2] <- zlim[2] + 2 * zstep # extend top limit to include the two new values above and na
cols <- c(col, na.color) # we construct the new color range by including: na.color and na.outside
nx <- ncol(z)
ny <- nrow(z)
obj.z <- list(x=1:ny, y=1:nx, z=z[ny:1,])
axis.args <- c(as.list(axis.args), cex = 1.5)
image.plot(obj.z, xlab=xlab, ylab='',  xlim=c(1,ny), ylim=c(1,nx), zlim=zlim, axis.args = axis.args, col=cols, xaxt="n", yaxt="n", ...)
rect(47,0,60,55, col="white", border="white", xpd=TRUE)
# Plot only the legend with original cutoffs
if(legend) image.plot(obj.z, xlab=xlab, ylab='',  xlim=c(1,ny), ylim=c(1,nx), zlim=zlim_orig, axis.args = axis.args, col=col, legend.only=TRUE, ...)
}
axis.args <- c(as.list(axis.args), cex = 1.5)
sum(mask3D==1)
beta1_est <- beta2_est <- mask3D
beta1_est[mask3D==1] <- betas[,1]
beta2_est[mask3D==1] <- betas[,2]
image(beta1_est)
beta1_est[mask3D==0] <- beta2_est[mask3D==0] <- NA
image(beta1_est)
summary(betas[,1])
image.nan(beta1_est, zlim=c(-0.2,1.4))
#set palette for beta maps
pal <- c('blue','turquoise','yellow','orange','red','darkred')
rf <- colorRampPalette(pal)   # make colors
r3 <- rf(64)
image.nan(beta1_est, zlim=c(-0.2,1.4), col=cols, na.color='white')
cols <- rf(64)
rm(r3)
image.nan(beta1_est, zlim=c(-0.2,1.4), col=cols, na.color='white')
image.nan(beta1_est, zlim=c(0,1.4), col=cols, na.color='white')
image.nan(beta1_est, zlim=c(-0.2,1.5), col=cols, na.color='white')
#set palette for beta maps
pal <- c('purple','blue','turquoise','yellow','orange','red','darkred')
rf <- colorRampPalette(pal)   # make colors
cols <- rf(64)
image.nan(beta1_est, zlim=c(-0.2,1.5), col=cols, na.color='white')
image.nan(beta1_est, zlim=c(-0.3,1.5), col=cols, na.color='white')
image.nan(beta1_est, zlim=c(-0.2,1.4), col=cols, na.color='white')
image.nan(beta1_est, zlim=c(-0.2,1.3), col=cols, na.color='white')
image.nan(beta1_est, zlim=c(-0.2,1.3), col=cols, na.color='white', axis.args=list(at=seq(0,1.2,0.3)))
summary(betas[,1])
summary(betas[,2])
image.nan(beta1_est, zlim=c(-0.25,1.4), col=cols, na.color='white', axis.args=list(at=seq(0,1.25,0.25)))
image.nan(beta1_est, zlim=c(-0.25,1.4), col=cols, na.color='white', axis.args=list(at=seq(-0.2,1.4,0.2)))
image.nan(beta2_est, zlim=c(-0.25,1.4), col=cols, na.color='white', axis.args=list(at=seq(-0.2,1.4,0.2)))
names(result)
thetas <- result$theta_posteriors
head(thetas)
library(ggplot2)
thetas <- result$theta_posteriors
ggplot(thetas, aes(x=value, y=density, color=param, group=param)) + geom_line() +
facet_grid(. ~ beta, scales='free')
ggplot(thetas, aes(x=value, y=density, color=beta, group=beta)) + geom_line() +
facet_grid(. ~ param, scales='free')
BayesGLMfMRI <- function(data, vertices, faces, mesh, mask, scale=TRUE){
#check whether data is a list OR a session (for single-session analysis)
#check whether each element of data is a session (use is.session)
# V0 = full number of data locations
# V = masked number of data locations
# T = length of time series for each session (vector)
# K = number of unique tasks in all sessions
#need to check that sessions are consistent in terms of V, K?
#INLA:::inla.dynload.workaround() #avoid error on creating mesh
#check that only mesh OR vertices+faces supplied
has_mesh <- !missing(mesh)
has_verts_faces <- !missing(vertices) & !missing(faces)
has_howmany <- has_mesh + has_verts_faces
if(has_howmany != 1) stop('Must supply EITHER mesh OR vertices and faces.')
#maybe also allow the user to supply a mesh object
#if mesh and mask both supplied, will need to deal with that...
#check that all elements of the data list are valid sessions and have the same number of locations and tasks
session_names <- names(data)
n_sess <- length(session_names)
if(!is.list(data)) stop('I expect data to be a list, but it is not')
data_classes <- sapply(data, 'class')
if(! all.equal(unique(data_classes),'list')) stop('I expect data to be a list of lists (sessions), but it is not')
V <- ncol(data[[1]]$BOLD)
K <- ncol(data[[1]]$design)
for(s in 1:n_sess){
if(! is.session(data[[s]])) stop('I expect each element of data to be a session object, but at least one is not (see `is.session`).')
if(ncol(data[[s]]$BOLD) != V) stop('All sessions must have the same number of data locations, but they do not.')
if(ncol(data[[s]]$design) != K) stop('All sessions must have the same number of tasks (columns of the design matrix), but they do not.')
}
if(missing(mesh)) {
if(missing(mask)) mesh <- make_mesh(vertices, faces)
if(!missing(mask)) mesh <- make_mesh(vertices, faces, mask)
}
spde <- inla.spde2.matern(mesh)
#areas <- compute_vertex_areas(mesh)
#collect data and design matrices
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
if(!missing(mask)) BOLD_s <- BOLD_s[,mask==1]
#scale data to represent % signal change
BOLD_s <- scale_timeseries(t(BOLD_s))
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
#construct betas and repls objects
replicates_list <- organize_replicates(n_sess=n_sess, n_task=K, mesh=mesh)
betas <- replicates_list$betas
repls <- replicates_list$repls
#organize the formula and data objects
formula <- make_formula(beta_names = names(betas), repl_names = names(repls), hyper_initial = c(-2,2))
formula <- as.formula(formula)
#formula <- y ~ -1 + f(bbeta1, model = spde, replicate = repl1, hyper = list(theta = list(initial = c(-2, 2)))) +
# f(bbeta2, model = spde, replicate = repl2, hyper = list(theta = list(initial = c(-2, 2))))
model_data <- make_data_list(y=y_all, X=X_all_list, betas=betas, repls=repls)
#estimate model using INLA
INLA_result <- estimate_model(formula=formula, data=model_data, A=model_data$X, prec_initial=1)
#extract useful stuff from INLA model result
beta_estimates <- extract_estimates(object=INLA_result, session_names=session_names) #posterior means of latent task field
theta_posteriors <- get_posterior_densities(object=INLA_result, spde) #hyperparameter posterior densities
#identify areas of activation if activation threshold(s) specified by user
#construct object to be returned
result <- list(model=INLA_result, mesh=mesh, sessions=session_names, beta_estimates=beta_estimates, theta_posteriors=theta_posteriors)
return(result)
}
result <- BayesGLMfMRI(data, mesh=mesh)
roxygenize()
library(roxygen2)
roxygenize()
