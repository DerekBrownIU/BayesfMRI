data <- list(single_session = session)
result <- BayesGLM(data, mesh=mesh)
data
class(data)
dim(data$single_session$BOLD)
#check that all elements of the data list are valid sessions and have the same number of locations and tasks
session_names <- names(data)
n_sess <- length(session_names)
session_names
n_sess
V <- ncol(data[[1]]$BOLD) #number of data locations
K <- ncol(data[[1]]$design) #number of tasks
V
K
spde <- inla.spde2.matern(mesh)
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
#scale data to represent % signal change (or just center if scale=FALSE)
BOLD_s <- scale_timeseries(t(BOLD_s), scale=scale)
design_s <- scale(data[[s]]$design, scale=FALSE) #center design matrix to eliminate baseline
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
s
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
BOLD_s
class(BOLD_s)
scale=TRUE
#scale data to represent % signal change (or just center if scale=FALSE)
BOLD_s <- scale_timeseries(t(BOLD_s), scale=scale)
design_s <- scale(data[[s]]$design, scale=FALSE) #center design matrix to eliminate baseline
dim(BOLD_s)
mask3D <- mask*mask2
mask3D[1:10,] <- 0
mask3D[,1:10] <- 0
mask3D <- mask*mask2
#mask3D[1:20,] <- 0
mask3D[,1:20] <- 0
mask3D[25:46,] <- 0
mask3D[,25:55] <- 0
mask_vec <- mask3D[mask3D_orig==1]
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
mesh <- inla.mesh.2d(loc = xy.in, max.edge = 100)
## Create a matrix to translate between original and mesh locations
Amat <- inla.spde.make.A(mesh, loc=xy.in)
## Read in timeseries data
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
dat <- dat[,mask_vec==1]
dim(dat)
dat <- dat[1:40,]
dim(dat)
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
dim(Z)
Z <- Z[1:40,]
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
data <- list(single_session = session)
result <- BayesGLM(data, mesh=mesh)
object=result
names(result)
result$beta_names
name='bbeta1'
threshold=0
alpha=0.05
area.limit=NULL
session_names <- object$session_names
n_sess <- length(session_names)
n_vox <- mesh$n
n_vox
INLA_result <- object$INLA_result
if(length(INLA_result$summary.random[[1]]$mean) != n_vox*n_sess) stop('Length of estimate vectors must equal number of sessions X number of voxels')
act <- vector('list', n_sess)
names(act) <- session_names
v=1
sess_name <- session_names[v]
inds_v <- (1:n_vox) + (v-1)*n_vox #indices of beta vector corresponding to session v
res.exc <- excursions.inla(INLA_result, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.1)
## Read in the mask
mask <- as.matrix(read.table("example/Mask"))
mask2 <- as.matrix(read.table("example/Mask2"))
mask3D <- mask*mask2
mask3D_orig <- mask3D
mask3D[1:20,] <- 0
mask3D[,1:20] <- 0
mask_vec <- mask3D[mask3D_orig==1]
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
mesh <- inla.mesh.2d(loc = xy.in, max.edge = 100)
## Create a matrix to translate between original and mesh locations
Amat <- inla.spde.make.A(mesh, loc=xy.in)
## Read in timeseries data
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
dat <- dat[,mask_vec==1]
dat <- dat[1:40,]
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
Z <- Z[1:40,]
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
data <- list(single_session = session)
result <- BayesGLM(data, mesh=mesh)
object=result
name='bbeta1'
threshold
session_names <- object$session_names
n_sess <- length(session_names)
n_vox <- mesh$n
INLA_result <- object$INLA_result
if(length(INLA_result$summary.random[[1]]$mean) != n_vox*n_sess) stop('Length of estimate vectors must equal number of sessions X number of voxels')
act <- vector('list', n_sess)
names(act) <- session_names
v
sess_name <- session_names[v]
inds_v <- (1:n_vox) + (v-1)*n_vox #indices of beta vector corresponding to session v
res.exc <- excursions.inla(INLA_result, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.1)
rnorm(method='hello')
tmp <- <- excursions.inla.no.spurious(INLA_result, mesh=mesh, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, area.limit = area.limit, use.continuous=FALSE, verbose=FALSE)
tmp <- excursions.inla.no.spurious(INLA_result, mesh=mesh, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, area.limit = area.limit, use.continuous=FALSE, verbose=FALSE)
area.limit
length(res.exc$E)
res.exc$E
tmp$E
area.limit=5
res.exc <- excursions.inla.no.spurious(INLA_result, mesh=mesh, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, area.limit = area.limit, use.continuous=FALSE, verbose=FALSE)
area.limit=60
res.exc <- excursions.inla.no.spurious(INLA_result, mesh=mesh, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, area.limit = area.limit, use.continuous=FALSE, verbose=FALSE)
res.exc$F
res.exc$G
res.exc$E
res.exc <- excursions.inla(INLA_result, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.1)
res.exc$E
res.exc$F
res.exc$G
res.exc$M
res.exc$mean
res.exc$vars
res.exc$rho
res.exc$meta
area.limit=NULL
result <- vector('list', n_sess)
names(result) <- session_names
for(v in 1:n_sess){
sess_name <- session_names[v]
inds_v <- (1:n_vox) + (v-1)*n_vox #indices of beta vector corresponding to session v
if(is.null(area.limit)){
res.exc <- excursions.inla(INLA_result, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.2)
} else {
res.exc <- excursions.inla.no.spurious(INLA_result, mesh=mesh, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, area.limit = area.limit, use.continuous=FALSE, verbose=FALSE)
}
act_v <- res.exc$E[inds_v]
act_v[is.na(act_v)] <- 0
result[[v]] <- list(active=act_v, excursions_result=res.exc)
}
## Read in the mask
mask <- as.matrix(read.table("example/Mask"))
sum(mask3D)
sum(mask3D_orig)
## Read in the mask
mask <- as.matrix(read.table("example/Mask"))
mask2 <- as.matrix(read.table("example/Mask2"))
mask3D <- mask*mask2
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
mesh <- inla.mesh.2d(loc = xy.in, boundary = boundary, max.edge = c(2, 4))
mesh <- inla.mesh.2d(loc = xy.in, boundary = boundary, max.edge = c(2, 4))
## Create a matrix to translate between original and mesh locations
Amat <- inla.spde.make.A(mesh, loc=xy.in)
## Read in timeseries data
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
dat <- dat[1:40,]
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
Z <- Z[1:40,]
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
data <- list(single_session = session)
result <- BayesGLM(data, mesh=mesh)
object = result
session_names <- object$session_names
n_sess <- length(session_names)
n_vox <- mesh$n
INLA_result <- object$INLA_result
if(alpha > 1 | alpha < 0) stop('alpha value must be between 0 and 1, and it is not')
if(length(INLA_result$summary.random[[1]]$mean) != n_vox*n_sess) stop('Length of estimate vectors must equal number of sessions X number of voxels')
result <- vector('list', n_sess)
names(result) <- session_names
v=1
sess_name <- session_names[v]
inds_v <- (1:n_vox) + (v-1)*n_vox #indices of beta vector corresponding to session v
res.exc <- excursions.inla(INLA_result, name=name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.2)
## Read in timeseries data
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
data <- list(single_session = session)
result <- BayesGLM(data, mesh=mesh)
object=result
field_name='bbeta1'
threshold
alpha
area.limit
session_names <- object$session_names
n_sess <- length(session_names)
n_vox <- mesh$n
INLA_result <- object$INLA_result
if(alpha > 1 | alpha < 0) stop('alpha value must be between 0 and 1, and it is not')
if(length(INLA_result$summary.random[[1]]$mean) != n_vox*n_sess) stop('Length of estimate vectors must equal number of sessions X number of voxels')
result <- vector('list', n_sess)
names(result) <- session_names
v
sess_name <- session_names[v]
inds_v <- (1:n_vox) + (v-1)*n_vox #indices of beta vector corresponding to session v
res.exc <- excursions.inla(INLA_result, name=field_name, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.2)
dim(session$BOLD)
a <- vector('list', 3)
a[[1]] <- vector('list', 2)
names(a) <- 'b', 'c'
names(a) <- c('b', 'c')
tmp <- 'b'
a
a[[1]]$b <- 'hello!'
a[[1]]$b
a[[1]]$tmp
a[[1]]$`tmp``
a[[1]]$`tmp`
field_name = NULL
model_obj=object
class(model_obj)
session_names <- model_obj$session_names
n_sess <- length(session_names)
n_vox <- mesh$n
if(is.null(field_name)) field_name <- model_obj$beta_names
field_name
if(!any(field_name %in% model_obj$beta_names)) stop("Please specify only field names that corresponds to one of the latent fields (i.e. 'bbeta1').")
if(alpha > 1 | alpha < 0) stop('alpha value must be between 0 and 1, and it is not')
if(length(model_obj$INLA_result$summary.random[[1]]$mean) != n_vox*n_sess) stop('Length of estimate vectors must equal number of sessions X number of voxels')
result <- vector('list', n_sess)
names(result) <- session_names
v=1
sess_name <- session_names[v]
inds_v <- (1:n_vox) + (v-1)*n_vox #indices of beta vector corresponding to session v
#loop over latent fields
result[[v]] <- vector('list', length(field_name))
names(result[[v]]) <- field_name
f=field_name[1]
res.exc <- excursions.inla(model_obj$INLA_result, name=f, ind=inds_v, u=threshold, type='>', method='QC', alpha=alpha, F.limit=0.2)
act_v <- res.exc$E[inds_v]
act_v[is.na(act_v)] <- 0
result[[v]][[which(field_name==f)]] <- list(active=act_v, excursions_result=res.exc)
result
class(res.exc)
model_obj$mesh$n
n_vox
dim(model_obj$beta_estimates)
dim(model_obj$beta_estimates$single_session)
res.exc$E[inds_v]
library(BayesfMRI)
library(roxygen2)
library(roxygen2md)
roxygenize()
roxygenize()
roxygenize()
library(BayesfMRI)
library(BayesfMRI)
roxygenize()
library(BayesfMRI)
library(BayesfMRI)
roxygenize()
library(BayesfMRI)
roxygenize()
library(BayesfMRI)
roxygenize()
sessionInfo()
inla.pardiso()
inla.pardiso()
inla.pardiso.check()
library(INLA)
inla.pardiso()
library(devtools)
install_github('mandymejia/BayesfMRI')
install.packages("available")
library(available)
available('BayesfMRI')
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(BayesfMRI)
## Read in the mask
mask <- as.matrix(read.table("example/Mask"))
mask2 <- as.matrix(read.table("example/Mask2"))
mask3D <- mask*mask2
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
mesh <- inla.mesh.2d(loc = xy.in, boundary = boundary, max.edge = c(2, 4))
library(INLA)
## Read in the mask
mask <- as.matrix(read.table("example/Mask"))
mask2 <- as.matrix(read.table("example/Mask2"))
mask3D <- mask*mask2
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
mesh <- inla.mesh.2d(loc = xy.in, boundary = boundary, max.edge = c(2, 4))
## Create a matrix to translate between original and mesh locations
Amat <- inla.spde.make.A(mesh, loc=xy.in)
## Plot mask and mesh
image(t(mask3D), xaxt='n', yaxt='n', col=c('white','black'))
plot(mesh, main='')
## Read in timeseries data
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
## Plot task regressors over time
plot(z1, type='l', ylab='', main='HRF Task Regressors')
lines(z2, col='red')
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
data <- list(single_session = session)
result <- BayesGLM(data, mesh=mesh)
#check that all elements of the data list are valid sessions and have the same number of locations and tasks
session_names <- names(data)
n_sess <- length(session_names)
if(!is.list(data)) stop('I expect data to be a list, but it is not')
data_classes <- sapply(data, 'class')
if(! all.equal(unique(data_classes),'list')) stop('I expect data to be a list of lists (sessions), but it is not')
V <- ncol(data[[1]]$BOLD) #number of data locations
K <- ncol(data[[1]]$design) #number of tasks
spde <- inla.spde2.matern(mesh)
#collect data and design matrices
y_all <- c()
X_all_list <- NULL
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
#scale data to represent % signal change (or just center if scale=FALSE)
BOLD_s <- scale_timeseries(t(BOLD_s), scale=scale)
design_s <- scale(data[[s]]$design, scale=FALSE) #center design matrix to eliminate baseline
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
vertices = NULL
faces = NULL
scale=TRUE
return_INLA_result=TRUE
for(s in 1:n_sess){
#extract and mask BOLD data for current session
BOLD_s <- data[[s]]$BOLD
#scale data to represent % signal change (or just center if scale=FALSE)
BOLD_s <- scale_timeseries(t(BOLD_s), scale=scale)
design_s <- scale(data[[s]]$design, scale=FALSE) #center design matrix to eliminate baseline
#regress nuisance parameters from BOLD data and design matrix
if('nuisance' %in% names(data[[s]])){
design_s <- data[[s]]$design
nuisance_s <- data[[s]]$nuisance
y_reg <- nuisance_regress(BOLD_s, nuisance_s)
X_reg <- nuisance_regress(design_s, nuisance_s)
} else {
y_reg <- BOLD_s
X_reg <- data[[s]]$design
}
#set up data and design matrix
data_org <- organize_data(y_reg, X_reg)
y_vec <- data_org$y
X_list <- list(data_org$A)
names(X_list) <- session_names[s]
y_all <- c(y_all, y_vec)
X_all_list <- c(X_all_list, X_list)
}
#construct betas and repls objects
replicates_list <- organize_replicates(n_sess=n_sess, n_task=K, mesh=mesh)
betas <- replicates_list$betas
repls <- replicates_list$repls
beta_names <- names(betas)
repl_names <- names(repls)
n_beta <- length(names(betas))
hyper_initial <- c(-2,2)
hyper_initial <- rep(list(hyper_initial), n_beta)
hyper_vec <- paste0(', hyper=list(theta=list(initial=', hyper_initial, '))')
formula_vec <- paste0('f(',beta_names, ', model = spde, replicate = ', repl_names, hyper_vec, ')')
formula_vec <- c('y ~ -1', formula_vec)
formula_str <- paste(formula_vec, collapse=' + ')
formula <- as.formula(formula_str, env = globalenv())
model_data <- make_data_list(y=y_all, X=X_all_list, betas=betas, repls=repls)
#estimate model using INLA
INLA_result <- estimate_model(formula=formula, data=model_data, A=model_data$X, spde=spde, prec_initial=1)
spde
summary(spde)
formula
class(model_data)
names(model_data)
class(model_data$bbeta1)
class(replicates_list)
class(replicates_list$betas)
names(replicates_list$betas)
class(replicates_list$betas$bbeta1)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
## Read in timeseries data
dat2 <- as.matrix(read.csv('example/FWHM20_NoisyData_2.csv', header=FALSE))
library(BayesfMRI)
library(INLA)
library(reshape2)
library(dplyr)
library(dplyr)
library(ggplot2)
load('example/Mask.Rdata') #mask3D
## Create a mesh using inla.mesh.2d
xy.in <- which(mask3D==1, arr.ind=TRUE)[,2:1]
boundary <- inla.nonconvex.hull(xy.in, resolution = 100)
mesh <- inla.mesh.2d(loc = xy.in, boundary = boundary, max.edge = c(2, 4))
## Create a matrix to translate between original and mesh locations
Amat <- inla.spde.make.A(mesh, loc=xy.in)
dat <- as.matrix(read.csv('example/FWHM20_NoisyData_1.csv', header=FALSE))
## Construct design matrix
z1 <- as.matrix(read.table('example/Z1.txt'))
z2 <- as.matrix(read.table('example/Z2.txt'))
Z <- cbind(z1, z2)
## Plot task regressors over time
plot(z1, type='l', ylab='', main='HRF Task Regressors')
lines(z2, col='red')
## Build session data
session <- list(BOLD = dat, design = Z)
is.session(session)
## Read in timeseries data
dat2 <- as.matrix(read.csv('example/FWHM20_NoisyData_2.csv', header=FALSE))
## Build session data
session2 <- list(BOLD = dat2, design = Z)
is.session(session2)
data <- list(sess1 = session, sess2 = session2)
result <- BayesfMRI::BayesGLM(data, mesh=mesh)
install.packages('alr4')
library(alr4)
View(BGSgirls)
min(5, NULL)
x <- rnorm(10000)
install.packages('entropy')
entropy(x)
library(entropy)
entropy(x)
log(sqrt(2*pi*exp(1)))
install.packages('DescTools')
library(DescTools)
h <- hist(x)
h <- hist(x, breaks=100)
names(h)
entropy(h$counts)
h <- hist(x, breaks=1000)
entropy(h$counts)
h <- hist(x, breaks=50)
entropy(h$counts)
library(devtools)
install_github('mandymejia/BayesfMRI')
