parallel <- FALSE
beta.post.samps <- apply(theta.tmp, MARGIN=1, FUN=beta.posterior.thetasamp, spde=spde, Xcros.all, Xycros.all, thresholds=thresholds, alpha=alpha, ind_beta=ind_beta)
} else {
max_no_cores <- min(detectCores() - 1, 25)
no_cores <- min(max_no_cores, no_cores)
cl <- makeCluster(no_cores)
beta.post.samps <- parApply(cl, theta.tmp, MARGIN=1, FUN=beta.posterior.thetasamp, spde=spde, K=K, M, Xcros.all, Xycros.all, thresholds=thresholds, alpha=0.01, ind_beta=ind_beta)
print(Sys.time() - t0)
stopCluster(cl)
}
#organize samples
U <- length(thresholds)
mu.tot <- matrix(nrow=K*n.mesh, ncol=nsamp)
F.tot <- rep(list(rep(list(matrix(nrow=n.mesh, ncol=nsamp)), K)), U) #for each activation threshold and task, a Vx50 matrix
for(itheta in 1:nsamp){
mu.tot[,itheta] <- beta.post.samps[[itheta]]$mu
for(u in 1:U){
for(k in 1:K){
F.tot[[u]][[k]][,itheta] <- beta.post.samps[[itheta]]$F[[u]][,k]
}
}
}
# Computing posterior quantities of beta, summing over theta')
### Sum over samples using weights, combine hemispheres (< 1 sec)
betas.all <- matrix(0, nrow=n.mesh, ncol=K)
probs.all <- array(0, dim=c(n.mesh, K, U)) #last dimension is for different activation thresholds
#posterior mean
beta.pop <- as.vector(mu.tot%*%wt)
for(k in 1:K){
beta.pop.k <- beta.pop[ind_beta[[k]]]
betas.all[,k] <- as.vector(beta.pop.k)
}
#posterior probabilities
for(u in 1:U){
for(k in 1:K){
F.pop.uk <- as.vector(F.tot[[u]][[k]]%*%wt)
probs.all[,k,u] <- as.vector(F.pop.uk)
}
}
result <- list(beta_estimates = betas.all, active_beta_probs = probs.all)
class(result) <- "BayesGLM_group"
return(result)
}#end loop over hemispheres
result.grp <- BayesGLM_group(result.lst, A = Amat, thresholds = 0)
thresholds = 0
thresholds[1]
# Find the numnber of subjects.
subject_names <- names(result)
M <- length(subject_names)
spde <- inla.spde2.matern(result[[1]]$mesh)
# Find the numnber of subjects.
subject_names <- names(result)
M <- length(subject_names)
M
spde <- inla.spde2.matern(result[[1]]$mesh)
result[[1]]$mesh
names(result[[1]])
result
names(result.lst$sub1)
result <- result.lst
# Find the numnber of subjects.
subject_names <- names(result)
M <- length(subject_names)
spde <- inla.spde2.matern(result[[1]]$mesh)
result.grp <- BayesGLM_group(result.lst, A = Amat, thresholds = 0)
names(result.grp)
# Read beta estimates
beta.tot <- result.grp$beta_estimates
dim(beta.tot)
n.mesh
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(knitr)
library(rgl)
knit_hooks$set(webgl = hook_webgl)
library(ggplot2)
visualize_vec2img <- function(values, field_names, xy.inds, pal=NULL, gradient2=FALSE, zlim=NULL){
#values is a matrix where each column is a vectorized, masked image
#names are the names of the fields corresponding to each column of values
#xy.in are the col- and row-indices in the original image corresponding to the rows of values
#pal is the color palette to use for the image
#zlim is a vector of the lower and upper limits for the intensity values
values_df <- data.frame(value = as.vector(values),
field = rep(field_names, each=length(values)/length(field_names)),
row = xy.inds[,1],
col = xy.inds[,2])
if(!is.null(zlim)){
print(paste0(sum(values_df$value > zlim[2]), ' pixels above upper z-limit')) #very few values
print(paste0(sum(values_df$value < zlim[1]), ' pixels above upper z-limit')) #very few values
values_df$value[values_df$value > zlim[2]] <- zlim[2]
values_df$value[values_df$value < zlim[1]] <- zlim[1]
}
p <- ggplot(values_df) +
geom_tile(aes(x = 41-row, y = col, color = value, fill = value)) +
facet_grid(. ~ field) + xlab('') + ylab('') +
theme_bw() + theme(panel.grid=element_blank())
if(!is.null(pal)){
p <- p + scale_color_gradientn("", colors=pal, na.value = "black", limits=zlim) +
scale_fill_gradientn("", colors=pal, na.value = "black", limits=zlim)
} else if (gradient2==TRUE) {
p <- p + scale_color_gradient2("", na.value = "black", limits=zlim) +
scale_fill_gradient2("", na.value = "black", limits=zlim)
} else {
p <- p + scale_color_gradient("", na.value = "black", limits=zlim) +
scale_fill_gradient("", na.value = "black", limits=zlim)
}
return(p)
}
visualize_vec2img(
values = Amat %*% result$beta_estimates$single_session,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
library(ggplot2)
visualize_vec2img <- function(values, field_names, xy.inds, pal=NULL, gradient2=FALSE, zlim=NULL){
#values is a matrix where each column is a vectorized, masked image
#names are the names of the fields corresponding to each column of values
#xy.in are the col- and row-indices in the original image corresponding to the rows of values
#pal is the color palette to use for the image
#zlim is a vector of the lower and upper limits for the intensity values
values_df <- data.frame(value = as.vector(values),
field = rep(field_names, each=length(values)/length(field_names)),
row = xy.inds[,1],
col = xy.inds[,2])
if(!is.null(zlim)){
print(paste0(sum(values_df$value > zlim[2]), ' pixels above upper z-limit')) #very few values
print(paste0(sum(values_df$value < zlim[1]), ' pixels above upper z-limit')) #very few values
values_df$value[values_df$value > zlim[2]] <- zlim[2]
values_df$value[values_df$value < zlim[1]] <- zlim[1]
}
p <- ggplot(values_df) +
geom_tile(aes(x = 41-row, y = col, color = value, fill = value)) +
facet_grid(. ~ field) + xlab('') + ylab('') +
theme_bw() + theme(panel.grid=element_blank())
if(!is.null(pal)){
p <- p + scale_color_gradientn("", colors=pal, na.value = "black", limits=zlim) +
scale_fill_gradientn("", colors=pal, na.value = "black", limits=zlim)
} else if (gradient2==TRUE) {
p <- p + scale_color_gradient2("", na.value = "black", limits=zlim) +
scale_fill_gradient2("", na.value = "black", limits=zlim)
} else {
p <- p + scale_color_gradient("", na.value = "black", limits=zlim) +
scale_fill_gradient("", na.value = "black", limits=zlim)
}
return(p)
}
dim(Amat)
visualize_vec2img(
values = Amat %*% beta.tot,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
# Read activation regions
act_prob <- result.grp$active_beta_probs
dim(act_prob)
dim(Amat)
n.mesh
table(Amat)
table(as.vector(Amat))
dim(probs.all)
hist(as.vector(probs.all))
quantile(as.vector(probs.all))
thresholds
dim(act_prob)
u
u <- 1
visualize_vec2img(
values = Amat %*% act_prob[,,u]
field_names = c('beta1', 'beta2'),
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(0, 1)
)
# Read activation regions
act_prob <- result.grp$active_beta_probs
hist(as.vector(act_prob))
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(0, 1)
)
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
# zlim = c(0, 1)
)
visualize_vec2img(
values = Amat %*% beta.tot,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
# Read beta estimates
beta.tot <- result.grp$beta_estimates
# Visualize beta estimates
visualize_vec2img(
values = Amat %*% beta.tot,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
for(u in 1:length(thresholds)){
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(0, 1)
)
}
act_prob <- result.grp$active_beta_probs
for(u in 1:length(thresholds)){
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
gradient2=TRUE
)
}
for(u in 1:length(thresholds)){
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
gradient2=TRUE
)
}
for(u in 1:length(thresholds)){
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
xy.inds = xy.in[,2:1],
gradient2=TRUE
)
}
for(u in 1:length(thresholds)){
visualize_vec2img(
values = Amat %*% act_prob[,,u],
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
}
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
act_prob <- result.grp$active_beta_probs
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(act_prob))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
act_prob <- result.grp$active_beta_probs
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(act_prob))
values_all[as.vector(mask3D) == 1,] <- as.matrix(act_prob)
act_prob <- result.grp$active_beta_probs
for(u in 1:length(thresholds)){
visualize_vec2img(
values = Amat %*% act_prob[,,u],
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
for(u in 1:length(thresholds)){
values = Amat %*% act_prob[,,u],
for(u in 1:length(thresholds)){
values = Amat %*% act_prob[,,u]
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
visualize_vec2img(
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
}
# Read activation regions
act_prob <- result.grp$active_beta_probs
for(u in 1:length(thresholds)){
values = Amat %*% act_prob[,,u]
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
visualize_vec2img(
values = values_all,
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
}
# Read beta estimates
beta.tot <- result.grp$beta_estimates
# Visualize beta estimates
visualize_vec2img(
values = Amat %*% beta.tot,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
# Read activation regions
act_prob <- result.grp$active_beta_probs
for(u in 1:length(thresholds)){
values = Amat %*% act_prob[,,u]
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
visualize_vec2img(
values = values_all,
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
}
hist(values)
table(as.vector(values))
for(u in 1:length(thresholds)){
values = Amat %*% act_prob[,,u]
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
visualize_vec2img(
values = values_all,
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
}
# Visualize beta estimates
visualize_vec2img(
values = Amat %*% beta.tot,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
u
values = Amat %*% act_prob[,,u]
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
visualize_vec2img(
values = values_all,
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
#' Applies joint approach to group-level analysis to task fMRI data
#'
#' @param results Either (1) a list of length M of objects of class BayesGLM, or (2) a character vector of length M of file names output from the BayesGLM function. M is the number of subjects.
#' @param contrast A vector specifying the contrast of interest.  See Details for more information.
#' @param no_cores The number of cores to use for sampling in parallel
#' @param thresholds The vector of activation thresholds
#' @param alpha The significance level for activation
#'
#' @details The contrast vector specifies the group-level quantity of interest.  For example, the vector rep(1,M*K) would return the group average for each of K tasks;
#' the vector `c(rep(1,M1*K)`, `rep(-1,M2*K))` would return the difference between the average within two groups of size M1 and M2, respectively, for each of K tasks;
#' the vector `rep(rep(1,-1,0,0),each=V),M)` would return the difference between the first two tasks (of 4), averaged over all subjects.
#'
#' @return A list containing...
#' @export
#' @importFrom INLA inla.spde2.matern
#'
#' @examples \dontrun{}
BayesGLM_group <- function(results, A, contrasts = NULL, thresholds = 0, alpha = 0.05, no_cores=NULL){
#check whether data is a list OR a session (for single-session analysis)
#check whether each element of data is a session (use is.session)
# V = number of data locations
# T = length of time series for each session (vector)
# K = number of tasks for each subject (each subject must have the same tasks)
# M = number of subjects
#check that each subject-level object is of class BayesGLM_obj
#check that beta_names matches for all subjects
#check that mesh (triangle) matches for all subjects
#check that results argument is in one of the two correct formats
#set up A matrix using the contrasts argument
# #check that only mesh OR vertices+faces supplied
# has_mesh <- !is.null(mesh)
# has_verts_faces <- !is.null(vertices) & !is.null(faces)
# has_howmany <- has_mesh + has_verts_faces
# if(has_howmany != 1) stop('Must supply EITHER mesh OR vertices and faces.')
#
# #check that all elements of the data list are valid sessions and have the same number of locations and tasks
#
# if(!is.list(data)) stop('I expect data to be a list, but it is not')
#   data_classes <- sapply(data, 'class')
# if(! all.equal(unique(data_classes),'list')) stop('I expect data to be a list of lists (sessions), but it is not')
# Find the numnber of subjects.
subject_names <- names(result)
M <- length(subject_names)
spde <- inla.spde2.matern(result[[1]]$mesh)
# Collecting theta posteriors from subject models
theta.sub <- NULL
mu.theta.tmp <- Q.theta <- 0
for(m in 1:M){
# Save it in BayesGLM()
res.hyper <- result[[m]]$INLA_result$summary.hyperpar
mu.tmp <- result[[m]]$mu.theta
Q.tmp <- result[[m]]$Q.theta
mu.theta.tmp <- mu.theta.tmp + as.vector(Q.tmp%*%mu.tmp)
Q.theta <- Q.theta + Q.tmp
theta.sub <- cbind(theta.sub, res.hyper$mode)
rm(mu.tmp, Q.tmp)
}
mu.theta <- solve(Q.theta, mu.theta.tmp)
# Drawing samples from q(theta|y)
nsamp <- 50
logwt <- rep(NA, nsamp)
theta.tmp <-MASS::mvrnorm(nsamp, mu.theta, solve(Q.theta))
for(i in 1:nsamp){
logwt[i] <- F.logwt(theta.tmp[i,], spde, mu.theta, Q.theta, M)
}
#weights to apply to each posterior sample of theta
wt.tmp <- exp(logwt - max(logwt))
wt <- wt.tmp/(sum(wt.tmp))
## Create index vectors
K <- (dim(theta.tmp)[2] - 1)/2
n.mesh <- mesh$n
ind_beta <- list()
for(k in 1:K){
ind_beta[[k]] <- 1:n.mesh + (k-1)*n.mesh
}
## Compute cross-products for single session
A.lst <- vector("list", K)
for(k in 1:K){
A.lst[[k]] <- A
}
Amat.tot <- bdiag(A.lst)
Xcros.all <- Xycros.all <- vector("list", M)
for(m in 1:M){
y_vec <- result[[m]]$y
X_list <- result[[m]]$X
Xmat <- X_list[[1]]%*%Amat.tot
Xcros.all[[m]] <- crossprod(Xmat)
Xycros.all[[m]] <- crossprod(Xmat, y_vec)
}
#get posterior quantities of beta, conditional on a value of theta
if(is.null(no_cores)) {
parallel <- FALSE
beta.post.samps <- apply(theta.tmp, MARGIN=1, FUN=beta.posterior.thetasamp, spde=spde, Xcros.all, Xycros.all, thresholds=thresholds, alpha=alpha, ind_beta=ind_beta)
} else {
max_no_cores <- min(detectCores() - 1, 25)
no_cores <- min(max_no_cores, no_cores)
cl <- makeCluster(no_cores)
beta.post.samps <- parApply(cl, theta.tmp, MARGIN=1, FUN=beta.posterior.thetasamp, spde=spde, K=K, M, Xcros.all, Xycros.all, thresholds=thresholds, alpha=alpha, ind_beta=ind_beta)
print(Sys.time() - t0)
stopCluster(cl)
}
#organize samples
U <- length(thresholds)
mu.tot <- matrix(nrow=K*n.mesh, ncol=nsamp)
F.tot <- rep(list(rep(list(matrix(nrow=n.mesh, ncol=nsamp)), K)), U) #for each activation threshold and task, a Vx50 matrix
for(itheta in 1:nsamp){
mu.tot[,itheta] <- beta.post.samps[[itheta]]$mu
for(u in 1:U){
for(k in 1:K){
F.tot[[u]][[k]][,itheta] <- beta.post.samps[[itheta]]$F[[u]][,k]
}
}
}
# Computing posterior quantities of beta, summing over theta')
### Sum over samples using weights, combine hemispheres (< 1 sec)
betas.all <- matrix(0, nrow=n.mesh, ncol=K)
probs.all <- active.all <- array(0, dim=c(n.mesh, K, U)) #last dimension is for different activation thresholds
#posterior mean
beta.pop <- as.vector(mu.tot%*%wt)
for(k in 1:K){
beta.pop.k <- beta.pop[ind_beta[[k]]]
betas.all[,k] <- as.vector(beta.pop.k)
}
#posterior probabilities
for(u in 1:U){
for(k in 1:K){
F.pop.uk <- as.vector(F.tot[[u]][[k]]%*%wt)
E.pop.uk <- rep(0, length(F.pop.uk))
E.pop.uk[F.pop.uk > 1-alpha] <- 1
probs.all[,k,u] <- as.vector(F.pop.uk)
active.all[,k,u] <- as.vector(E.pop.uk)
}
}
#activation set
active <- probs.all
result <- list(beta_estimates = betas.all, ppm = probs.all, active = active.all)
class(result) <- "BayesGLM_group"
return(result)
}#end loop over hemispheres
result.grp <- BayesGLM_group(result.lst, A = Amat, thresholds = 0)
# Read beta estimates
beta.tot <- result.grp$beta_estimates
# Visualize beta estimates
visualize_vec2img(
values = Amat %*% beta.tot,
field_names = c('beta1', 'beta2'),
pal = c('purple','blue','turquoise','yellow','orange','red','darkred'),
xy.inds = xy.in[,2:1],
zlim = c(-0.3, 1.3)
)
# Read activation regions
active <- result.grp$active
values = Amat %*% active[,,u]
values_all <- matrix(NA, nrow=length(mask3D), ncol=ncol(values))
values_all[as.vector(mask3D) == 1,] <- as.matrix(values)
visualize_vec2img(
values = values_all,
field_names = c('beta1', 'beta2'),
gradient2=TRUE,
xy.in = which(mask3D >= 0, arr.ind=TRUE)
)
